{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ***Optimization Techniques***\n",
        "\n",
        "*   Gradient Descent algorithm\n",
        "\n",
        "*   Stochastic Gradient Descent algorithm\n",
        "*   BFGS algorithm\n",
        "\n",
        "*   LBFGS algorithm\n",
        "\n"
      ],
      "metadata": {
        "id": "P2Yha-qUBvTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import scipy.io\n",
        "import random"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:17:55.016697Z",
          "iopub.execute_input": "2023-04-18T18:17:55.017427Z",
          "iopub.status.idle": "2023-04-18T18:17:55.023683Z",
          "shell.execute_reply.started": "2023-04-18T18:17:55.017371Z",
          "shell.execute_reply": "2023-04-18T18:17:55.022294Z"
        },
        "trusted": true,
        "id": "InDgoYRyBvTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from CSV files\n",
        "x_tr = pd.read_csv('/kaggle/input/data-set/Final _dataset/X_train.csv', header=None).values\n",
        "print(\"x_tr\", x_tr.shape)\n",
        "\n",
        "y_tr = pd.read_csv('/kaggle/input/data-set/Final _dataset/Y_train.csv', header=None).values.flatten()\n",
        "y_tr = y_tr.reshape(y_tr.shape[0],1)\n",
        "print(\"y_tr\", y_tr.shape)\n",
        "\n",
        "x_test = pd.read_csv('/kaggle/input/data-set/Final _dataset/X_test.csv', header=None).values\n",
        "print(\"x_test\", x_test.shape)\n",
        "\n",
        "y_test = pd.read_csv('/kaggle/input/data-set/Final _dataset/Y_test.csv', header=None).values.flatten()\n",
        "y_test = y_test.reshape(y_test.shape[0],1)\n",
        "print(\"y_test\", y_test.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:17:57.241558Z",
          "iopub.execute_input": "2023-04-18T18:17:57.242193Z",
          "iopub.status.idle": "2023-04-18T18:17:58.151480Z",
          "shell.execute_reply.started": "2023-04-18T18:17:57.242147Z",
          "shell.execute_reply": "2023-04-18T18:17:58.150627Z"
        },
        "trusted": true,
        "id": "GqESlBx4BvTj",
        "outputId": "04353673-bbb4-4825-8c5a-145c034e342c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "x_tr (10000, 784)\ny_tr (10000, 1)\nx_test (1000, 784)\ny_test (1000, 1)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigma_sq(Z):\n",
        "    sigma_sq = 0\n",
        "    for i in range(len(Z)):\n",
        "        for j in range(len(Z)):\n",
        "            sigma_sq += (np.linalg.norm(Z[i] - Z[j]) ** 2)\n",
        "    sigma_sq = sigma_sq / (len(Z) ** 2)\n",
        "    return sigma_sq"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:18:00.655472Z",
          "iopub.execute_input": "2023-04-18T18:18:00.656382Z",
          "iopub.status.idle": "2023-04-18T18:18:00.662638Z",
          "shell.execute_reply.started": "2023-04-18T18:18:00.656340Z",
          "shell.execute_reply": "2023-04-18T18:18:00.661393Z"
        },
        "trusted": true,
        "id": "slQi5C0CBvTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sigma square for x_train data set\n",
        "\n",
        "sigma_sq(x_tr)\n",
        "\n",
        "# Saved the results as train_sigma_sq to avoid re-running"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:18:16.763805Z",
          "iopub.execute_input": "2023-04-18T18:18:16.764230Z",
          "iopub.status.idle": "2023-04-18T18:35:25.615386Z",
          "shell.execute_reply.started": "2023-04-18T18:18:16.764196Z",
          "shell.execute_reply": "2023-04-18T18:35:25.614198Z"
        },
        "trusted": true,
        "id": "47rp__-GBvTk",
        "outputId": "659c4701-0a8d-464b-c024-896fbc782519"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 64,
          "output_type": "execute_result",
          "data": {
            "text/plain": "103.46796422725427"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sigma square for x_test data set\n",
        "\n",
        "sigma_sq(x_test)\n",
        "\n",
        "# Saved the results as test_sigma_sq to avoid re-running"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:35:25.617301Z",
          "iopub.execute_input": "2023-04-18T18:35:25.617649Z",
          "iopub.status.idle": "2023-04-18T18:35:35.711142Z",
          "shell.execute_reply.started": "2023-04-18T18:35:25.617615Z",
          "shell.execute_reply": "2023-04-18T18:35:35.709892Z"
        },
        "trusted": true,
        "id": "2U1G9WcUBvTk",
        "outputId": "064ed192-80a9-4825-dbf6-38bd4dcfd1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 65,
          "output_type": "execute_result",
          "data": {
            "text/plain": "102.81865457345208"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saved sigma_square value for train and test data to avoid repetative running\n",
        "\n",
        "train_sigma_sq = math.sqrt(103.468)\n",
        "test_sigma_sq = math.sqrt(102.818)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:35:35.712807Z",
          "iopub.execute_input": "2023-04-18T18:35:35.713737Z",
          "iopub.status.idle": "2023-04-18T18:35:35.718693Z",
          "shell.execute_reply.started": "2023-04-18T18:35:35.713689Z",
          "shell.execute_reply": "2023-04-18T18:35:35.717931Z"
        },
        "trusted": true,
        "id": "zzKEijmCBvTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define RBF kernel\n",
        "def rbf_kernel(x1, x2, sigma_sq):\n",
        "    Rbf_K = np.exp(-np.linalg.norm(x1 - x2) ** 2 / (2 * sigma_sq ** 2))\n",
        "\n",
        "    return Rbf_K"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:35:35.721000Z",
          "iopub.execute_input": "2023-04-18T18:35:35.721616Z",
          "iopub.status.idle": "2023-04-18T18:35:35.737362Z",
          "shell.execute_reply.started": "2023-04-18T18:35:35.721583Z",
          "shell.execute_reply": "2023-04-18T18:35:35.736323Z"
        },
        "trusted": true,
        "id": "vapPHVk6BvTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_k(x_tr, sigma_sq):\n",
        "    S = len(x_tr)\n",
        "    tr_k = np.zeros((S, S))\n",
        "\n",
        "    for i in range(S):\n",
        "        for j in range(i, S):\n",
        "            tr_k[i, j] = rbf_kernel(x_tr[i], x_tr[j], sigma_sq)\n",
        "            tr_k[j, i] = tr_k[i, j]\n",
        "\n",
        "    return tr_k"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:35:35.739015Z",
          "iopub.execute_input": "2023-04-18T18:35:35.739698Z",
          "iopub.status.idle": "2023-04-18T18:35:35.750483Z",
          "shell.execute_reply.started": "2023-04-18T18:35:35.739661Z",
          "shell.execute_reply": "2023-04-18T18:35:35.749316Z"
        },
        "trusted": true,
        "id": "2xNwBb2dBvTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testing_k(test_x, train_x, sigma_sq):\n",
        "    test_k = np.zeros((len(test_x), len(train_x)))\n",
        "\n",
        "    for i in range(len(test_x)):\n",
        "        for j in range(len(train_x)):\n",
        "\n",
        "            test_k[i, j] = rbf_kernel(test_x[i], train_x[j], sigma_sq)\n",
        "\n",
        "    return test_k"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:35:35.751704Z",
          "iopub.execute_input": "2023-04-18T18:35:35.752063Z",
          "iopub.status.idle": "2023-04-18T18:35:35.763787Z",
          "shell.execute_reply.started": "2023-04-18T18:35:35.752022Z",
          "shell.execute_reply": "2023-04-18T18:35:35.762725Z"
        },
        "trusted": true,
        "id": "UA4zu0c8BvTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kernel for x_train data set\n",
        "\n",
        "Train_k = training_k(x_tr, train_sigma_sq)\n",
        "np.save('Train_k.npy', Train_k)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:35:35.765290Z",
          "iopub.execute_input": "2023-04-18T18:35:35.766347Z",
          "iopub.status.idle": "2023-04-18T18:46:30.933596Z",
          "shell.execute_reply.started": "2023-04-18T18:35:35.766298Z",
          "shell.execute_reply": "2023-04-18T18:46:30.932276Z"
        },
        "trusted": true,
        "id": "x7Zll_0CBvTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kernel for x_test data set\n",
        "\n",
        "Test_k = testing_k(x_test, x_tr, test_sigma_sq)\n",
        "np.save('Test_k.npy',Test_k)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:46:30.935169Z",
          "iopub.execute_input": "2023-04-18T18:46:30.935728Z",
          "iopub.status.idle": "2023-04-18T18:48:36.190868Z",
          "shell.execute_reply.started": "2023-04-18T18:46:30.935695Z",
          "shell.execute_reply": "2023-04-18T18:48:36.189683Z"
        },
        "trusted": true,
        "id": "GcqRYM9fBvTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the presaved kernel test and train files\n",
        "\n",
        "Train_k = np.load('/kaggle/input/data-set/Final _dataset/k_train.npy')\n",
        "Test_k = np.load('/kaggle/input/data-set/Final _dataset/k_test.npy')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:48:36.192110Z",
          "iopub.execute_input": "2023-04-18T18:48:36.192431Z",
          "iopub.status.idle": "2023-04-18T18:48:36.739374Z",
          "shell.execute_reply.started": "2023-04-18T18:48:36.192399Z",
          "shell.execute_reply": "2023-04-18T18:48:36.738219Z"
        },
        "trusted": true,
        "id": "oYLVlgQnBvTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sigmoid func\n",
        "def sigmoid(z):\n",
        "    sig = 1 / (1 + np.exp(-np.clip(z, -100, 100)))\n",
        "    return sig"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:48:36.743022Z",
          "iopub.execute_input": "2023-04-18T18:48:36.743667Z",
          "iopub.status.idle": "2023-04-18T18:48:36.749549Z",
          "shell.execute_reply.started": "2023-04-18T18:48:36.743626Z",
          "shell.execute_reply": "2023-04-18T18:48:36.747955Z"
        },
        "trusted": true,
        "id": "3-rpR8blBvTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  loss func\n",
        "def loss(w, y, kernel, lamb):\n",
        "    z = np.multiply(y, np.dot(kernel, w))\n",
        "    Loss = -np.sum(np.log(sigmoid(z))) + lamb * np.dot(w.T, w)\n",
        "    return Loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:48:36.751853Z",
          "iopub.execute_input": "2023-04-18T18:48:36.753139Z",
          "iopub.status.idle": "2023-04-18T18:48:36.761312Z",
          "shell.execute_reply.started": "2023-04-18T18:48:36.753086Z",
          "shell.execute_reply": "2023-04-18T18:48:36.760122Z"
        },
        "trusted": true,
        "id": "3qQv7o3GBvTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient\n",
        "def gradient(w, y, kernel, lamb):\n",
        "    z = np.multiply(y, np.dot(kernel, w))\n",
        "    grad = -np.dot(kernel.T, np.multiply(y, (1 - sigmoid(z)))) + 2 * lamb * w\n",
        "    return grad"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:48:36.763045Z",
          "iopub.execute_input": "2023-04-18T18:48:36.763580Z",
          "iopub.status.idle": "2023-04-18T18:48:36.773124Z",
          "shell.execute_reply.started": "2023-04-18T18:48:36.763532Z",
          "shell.execute_reply": "2023-04-18T18:48:36.772093Z"
        },
        "trusted": true,
        "id": "l7kSWjXyBvTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **GD_Algorithm**"
      ],
      "metadata": {
        "id": "ueiAKd-4BvTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GD_train(kernel, y, sigma_sq, lamb, lr):\n",
        "\n",
        "    loss_total = []\n",
        "    accuracy_tr = []\n",
        "    accuracy_test = []\n",
        "    I, J = kernel.shape\n",
        "    accuracy = 0\n",
        "    w_out = np.zeros((I,1))\n",
        "\n",
        "    w = np.zeros((I,1))\n",
        "    y = y.reshape(I,1)\n",
        "    threshold = 1e-5\n",
        "    iteration = 1200\n",
        "\n",
        "    for epoch in range(iteration):\n",
        "        prev_w = np.copy(w)\n",
        "        grad = gradient(w, y, kernel, lamb)\n",
        "        w -= lr * grad\n",
        "\n",
        "        tr_loss = loss(w, y, kernel, lamb)\n",
        "        tr_out = predict(kernel, w)\n",
        "        tr_a = np.mean(tr_out == y)\n",
        "        test_out = predict(Test_k, w)\n",
        "        test_a = np.mean(test_out == y_test.reshape(1000,1))\n",
        "\n",
        "        if test_a > accuracy:\n",
        "            accuracy = test_a\n",
        "            w_out = np.copy(w)\n",
        "        loss_total.append(tr_loss)\n",
        "        accuracy_tr.append(tr_a)\n",
        "        accuracy_test.append(test_a)\n",
        "\n",
        "        if (epoch) % 50 == 0:\n",
        "            print(f\"Epoch {epoch}: Train Loss = {tr_loss[0][0]:.3f} \\t Train Accuracy = {tr_a*100:.2f} %\")\n",
        "\n",
        "        if np.linalg.norm(grad) < threshold:\n",
        "            print(f\"Converged at Epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    return w_out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T18:59:06.399163Z",
          "iopub.execute_input": "2023-04-18T18:59:06.399939Z",
          "iopub.status.idle": "2023-04-18T18:59:06.412158Z",
          "shell.execute_reply.started": "2023-04-18T18:59:06.399869Z",
          "shell.execute_reply": "2023-04-18T18:59:06.410703Z"
        },
        "trusted": true,
        "id": "Gn8tAanYBvTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "def predict(kernel, w):\n",
        "\n",
        "    y_out = sigmoid(np.dot(kernel, w))\n",
        "    y_out[y_out > 0.5] = 1\n",
        "    y_out[y_out <= 0.5] = -1\n",
        "    return y_out"
      ],
      "metadata": {
        "id": "ZFC0EHS7Cw5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "w = GD_train(Train_k, y_tr, train_sigma_sq, lamb = 0.005, lr = 0.0005)\n",
        "print()\n",
        "\n",
        "# Testing the accuracy\n",
        "y_out = predict(Test_k,w)\n",
        "Test_accuracy = np.mean(y_out == y_test)\n",
        "print()\n",
        "print(f\"GD_test_accuracy = {Test_accuracy * 100 : .2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T19:03:24.479815Z",
          "iopub.execute_input": "2023-04-18T19:03:24.480290Z",
          "iopub.status.idle": "2023-04-18T19:06:32.516035Z",
          "shell.execute_reply.started": "2023-04-18T19:03:24.480249Z",
          "shell.execute_reply": "2023-04-18T19:06:32.514056Z"
        },
        "trusted": true,
        "id": "bzwCQxzxBvTn",
        "outputId": "6883380d-c398-4790-abce-17a44ee9605e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 0: Train Loss = 500000.204 \t Train Accuracy = 50.00 %\nEpoch 50: Train Loss = 500499.145 \t Train Accuracy = 50.00 %\nEpoch 100: Train Loss = 501621.540 \t Train Accuracy = 50.00 %\nEpoch 150: Train Loss = 478489.693 \t Train Accuracy = 52.23 %\nEpoch 200: Train Loss = 144195.640 \t Train Accuracy = 85.47 %\nEpoch 250: Train Loss = 137552.802 \t Train Accuracy = 86.20 %\nEpoch 300: Train Loss = 130265.237 \t Train Accuracy = 86.81 %\nEpoch 350: Train Loss = 125582.904 \t Train Accuracy = 87.31 %\nEpoch 400: Train Loss = 121219.833 \t Train Accuracy = 87.67 %\nEpoch 450: Train Loss = 116857.064 \t Train Accuracy = 88.12 %\nEpoch 500: Train Loss = 113251.137 \t Train Accuracy = 88.20 %\nEpoch 550: Train Loss = 483141.529 \t Train Accuracy = 51.87 %\nEpoch 600: Train Loss = 133545.672 \t Train Accuracy = 86.68 %\nEpoch 650: Train Loss = 120614.824 \t Train Accuracy = 87.99 %\nEpoch 700: Train Loss = 118218.393 \t Train Accuracy = 88.23 %\nEpoch 750: Train Loss = 115129.797 \t Train Accuracy = 88.50 %\nEpoch 800: Train Loss = 112003.876 \t Train Accuracy = 88.67 %\nEpoch 850: Train Loss = 109863.188 \t Train Accuracy = 88.94 %\nEpoch 900: Train Loss = 468015.103 \t Train Accuracy = 53.37 %\nEpoch 950: Train Loss = 212947.659 \t Train Accuracy = 78.79 %\nEpoch 1000: Train Loss = 115323.657 \t Train Accuracy = 88.62 %\nEpoch 1050: Train Loss = 112752.493 \t Train Accuracy = 88.78 %\nEpoch 1100: Train Loss = 110748.691 \t Train Accuracy = 88.91 %\nEpoch 1150: Train Loss = 108170.321 \t Train Accuracy = 89.13 %\n\n\nGD_test_accuracy =  90.60%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **SGD_Algorithm**"
      ],
      "metadata": {
        "id": "YNhzssMRBvTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SGD_train(Train_k, y_tr, Test_k, y_test, lamb, lr, b_s):\n",
        "\n",
        "    loss_tr = []\n",
        "    loss_test = []\n",
        "    accuracy_tr = []\n",
        "    accuracy_test = []\n",
        "\n",
        "    I = Train_k.shape[0]\n",
        "    J = Test_k.shape[0]\n",
        "    accuracy = 0\n",
        "    w_out = np.zeros((I,1))\n",
        "\n",
        "    w = np.zeros((I,1))\n",
        "    y_tr = y_tr.reshape(I,1)\n",
        "    y_test = y_test.reshape(J,1)\n",
        "    threshold = 1e-5\n",
        "    iterations = 1200\n",
        "\n",
        "    for epoch in range(iterations):\n",
        "        prev_w = np.copy(w)\n",
        "        indices = np.random.permutation(I)\n",
        "        num_batches = int(np.ceil(I / b_s))\n",
        "\n",
        "        for i in range(num_batches):\n",
        "            batch_indices = indices[i*b_s:(i+1)*b_s]\n",
        "            batch_K_Train = Train_k[batch_indices,:]\n",
        "            batch_y_tr = y_tr[batch_indices,:]\n",
        "            grad = gradient(w, batch_y_tr, batch_K_Train, lamb)\n",
        "            w -= lr * grad\n",
        "\n",
        "        tr_loss = loss(w, y_tr, Train_k, lamb)\n",
        "        test_loss = loss(w, y_test, Test_k, lamb)\n",
        "        tr_out = predict(Train_k, w)\n",
        "        test_out = predict(Test_k, w)\n",
        "        tr_a = np.mean(tr_out == y_tr)\n",
        "        test_a = np.mean(test_out == y_test)\n",
        "\n",
        "\n",
        "        if test_a > accuracy:\n",
        "            accuracy = test_a\n",
        "            w_out = np.copy(w)\n",
        "        loss_tr.append(tr_loss)\n",
        "        loss_test.append(test_loss)\n",
        "        accuracy_tr.append(tr_a)\n",
        "        accuracy_test.append(test_a)\n",
        "\n",
        "        if (epoch) % 50 == 0:\n",
        "            print(f\"Epoch {epoch}: Train Loss = {tr_loss[0][0]:.3f} \\t Train Accuracy = {tr_a*100:.2f} %\")\n",
        "\n",
        "        if (w - prev_w).any() < threshold:\n",
        "            print(f\"Converge at {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    return w_out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T19:13:28.276270Z",
          "iopub.execute_input": "2023-04-18T19:13:28.277134Z",
          "iopub.status.idle": "2023-04-18T19:13:28.292855Z",
          "shell.execute_reply.started": "2023-04-18T19:13:28.277083Z",
          "shell.execute_reply": "2023-04-18T19:13:28.291582Z"
        },
        "trusted": true,
        "id": "SoW0-5mlBvTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = SGD_train(Train_k, y_tr, Test_k, y_test, lamb = 0.005, lr = 0.0005, b_s=1)\n",
        "\n",
        "# Testing accuracy\n",
        "print()\n",
        "y_out = predict(Test_k,w)\n",
        "accuracy = np.mean(y_out == y_test)\n",
        "print(f\"Accuracy = {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T19:36:32.191392Z",
          "iopub.execute_input": "2023-04-18T19:36:32.191825Z",
          "iopub.status.idle": "2023-04-18T19:55:28.927785Z",
          "shell.execute_reply.started": "2023-04-18T19:36:32.191789Z",
          "shell.execute_reply": "2023-04-18T19:55:28.925920Z"
        },
        "trusted": true,
        "id": "zw_J8CsiBvTo",
        "outputId": "cec28a23-f938-4e21-9c1e-3636d44f4248"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 0: Train Loss = 3133.938 \t Train Accuracy = 87.24 %\nEpoch 50: Train Loss = 2389.262 \t Train Accuracy = 90.98 %\nEpoch 100: Train Loss = 2683.745 \t Train Accuracy = 89.62 %\nEpoch 150: Train Loss = 3702.762 \t Train Accuracy = 84.02 %\nEpoch 200: Train Loss = 2583.018 \t Train Accuracy = 90.36 %\nEpoch 250: Train Loss = 2376.595 \t Train Accuracy = 91.25 %\nEpoch 300: Train Loss = 2461.731 \t Train Accuracy = 90.86 %\nEpoch 350: Train Loss = 2407.520 \t Train Accuracy = 91.14 %\nEpoch 400: Train Loss = 2410.969 \t Train Accuracy = 90.81 %\nEpoch 450: Train Loss = 2570.672 \t Train Accuracy = 90.43 %\nEpoch 500: Train Loss = 2521.798 \t Train Accuracy = 90.33 %\nEpoch 550: Train Loss = 2514.721 \t Train Accuracy = 90.33 %\nEpoch 600: Train Loss = 2505.142 \t Train Accuracy = 90.61 %\nEpoch 650: Train Loss = 2417.261 \t Train Accuracy = 90.81 %\nEpoch 700: Train Loss = 2388.084 \t Train Accuracy = 90.86 %\nEpoch 750: Train Loss = 2527.004 \t Train Accuracy = 90.54 %\nEpoch 800: Train Loss = 3026.159 \t Train Accuracy = 87.94 %\nEpoch 850: Train Loss = 4445.296 \t Train Accuracy = 81.72 %\nEpoch 900: Train Loss = 2519.980 \t Train Accuracy = 90.63 %\nEpoch 950: Train Loss = 2441.909 \t Train Accuracy = 90.71 %\nEpoch 1000: Train Loss = 2984.908 \t Train Accuracy = 88.14 %\nEpoch 1050: Train Loss = 2415.437 \t Train Accuracy = 90.77 %\nEpoch 1100: Train Loss = 3284.258 \t Train Accuracy = 86.80 %\nEpoch 1150: Train Loss = 2380.180 \t Train Accuracy = 90.95 %\n\nAccuracy = 92.80%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = SGD_train(Train_k, y_tr, Test_k, y_test, lamb = 0.005, lr = 0.0005, b_s = 100)\n",
        "\n",
        "# Testing accuracy\n",
        "print()\n",
        "y_out = predict(Test_k,w)\n",
        "accuracy = np.mean(y_out == y_test)\n",
        "print(f\"Accuracy = {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T19:55:28.933910Z",
          "iopub.execute_input": "2023-04-18T19:55:28.935547Z",
          "iopub.status.idle": "2023-04-18T20:03:28.935755Z",
          "shell.execute_reply.started": "2023-04-18T19:55:28.935490Z",
          "shell.execute_reply": "2023-04-18T20:03:28.933947Z"
        },
        "trusted": true,
        "id": "hqMlM-lVBvTo",
        "outputId": "29db2588-5fef-4aa5-a7f9-495009c08d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 0: Train Loss = 187811.998 \t Train Accuracy = 50.00 %\nEpoch 50: Train Loss = 52826.973 \t Train Accuracy = 68.45 %\nEpoch 100: Train Loss = 14752.435 \t Train Accuracy = 87.48 %\nEpoch 150: Train Loss = 9864.406 \t Train Accuracy = 90.16 %\nEpoch 200: Train Loss = 8803.216 \t Train Accuracy = 91.65 %\nEpoch 250: Train Loss = 13060.206 \t Train Accuracy = 88.77 %\nEpoch 300: Train Loss = 96785.761 \t Train Accuracy = 56.76 %\nEpoch 350: Train Loss = 9019.100 \t Train Accuracy = 91.59 %\nEpoch 400: Train Loss = 10683.480 \t Train Accuracy = 90.03 %\nEpoch 450: Train Loss = 77567.776 \t Train Accuracy = 62.64 %\nEpoch 500: Train Loss = 7599.842 \t Train Accuracy = 92.44 %\nEpoch 550: Train Loss = 9932.924 \t Train Accuracy = 90.15 %\nEpoch 600: Train Loss = 7089.271 \t Train Accuracy = 92.60 %\nEpoch 650: Train Loss = 8699.906 \t Train Accuracy = 91.26 %\nEpoch 700: Train Loss = 7645.266 \t Train Accuracy = 92.54 %\nEpoch 750: Train Loss = 7178.130 \t Train Accuracy = 92.73 %\nEpoch 800: Train Loss = 7904.301 \t Train Accuracy = 92.49 %\nEpoch 850: Train Loss = 7282.728 \t Train Accuracy = 92.68 %\nEpoch 900: Train Loss = 8638.669 \t Train Accuracy = 91.74 %\nEpoch 950: Train Loss = 8664.826 \t Train Accuracy = 91.83 %\nEpoch 1000: Train Loss = 7923.636 \t Train Accuracy = 91.73 %\nEpoch 1050: Train Loss = 7786.264 \t Train Accuracy = 91.55 %\nEpoch 1100: Train Loss = 7712.467 \t Train Accuracy = 92.56 %\nEpoch 1150: Train Loss = 8382.100 \t Train Accuracy = 91.74 %\n\nAccuracy = 94.30%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **BFGS_Algorithm**"
      ],
      "metadata": {
        "id": "xKxCG-qjBvTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random data saving\n",
        "np.random.seed(14)\n",
        "random.seed(14)\n",
        "Inced_two = np.where(y_tr == 1)[0]\n",
        "Index_two = np.where(y_tr == -1)[0]\n",
        "np.random.shuffle(Inced_two)\n",
        "np.random.shuffle(Index_two)\n",
        "Inced_two = Inced_two[:2000]\n",
        "Index_two = Index_two[:2000]\n",
        "\n",
        "index_s = np.concatenate([Inced_two, Index_two])\n",
        "bfgs_x_tr = x_tr[index_s]\n",
        "bfgs_y_tr = y_tr[index_s]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:05:08.811857Z",
          "iopub.execute_input": "2023-04-18T20:05:08.812324Z",
          "iopub.status.idle": "2023-04-18T20:05:08.861417Z",
          "shell.execute_reply.started": "2023-04-18T20:05:08.812284Z",
          "shell.execute_reply": "2023-04-18T20:05:08.860304Z"
        },
        "trusted": true,
        "id": "kqvaPexOBvTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BFGS train kernel\n",
        "\n",
        "bfgs_k_train = training_k(bfgs_x_tr, train_sigma_sq)\n",
        "np.save('bfgs_k_train.npy', bfgs_k_train)\n",
        "\n",
        "# Saved as document to avoid re-running"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:05:11.328478Z",
          "iopub.execute_input": "2023-04-18T20:05:11.328930Z",
          "iopub.status.idle": "2023-04-18T20:06:44.480266Z",
          "shell.execute_reply.started": "2023-04-18T20:05:11.328891Z",
          "shell.execute_reply": "2023-04-18T20:06:44.478983Z"
        },
        "trusted": true,
        "id": "4R-KwRFWBvTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BFGS test kernel\n",
        "\n",
        "bfgs_k_test = testing_k(x_test, bfgs_x_tr, test_sigma_sq)\n",
        "np.save('bfgs_k_test.npy', bfgs_k_test)\n",
        "\n",
        "# Saved as document to avoid re-running"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:06:44.482268Z",
          "iopub.execute_input": "2023-04-18T20:06:44.482652Z",
          "iopub.status.idle": "2023-04-18T20:07:30.776374Z",
          "shell.execute_reply.started": "2023-04-18T20:06:44.482617Z",
          "shell.execute_reply": "2023-04-18T20:07:30.775081Z"
        },
        "trusted": true,
        "id": "sNaobkr9BvTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved BFGS kernel data for training and testing\n",
        "\n",
        "bfgs_k_train = np.load('/kaggle/input/bgfsdata/bfgs_k_train.npy')\n",
        "bfgs_k_test = np.load('/kaggle/input/bgfsdata/bfgs_k_test.npy')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:07:30.777931Z",
          "iopub.execute_input": "2023-04-18T20:07:30.778297Z",
          "iopub.status.idle": "2023-04-18T20:07:34.188504Z",
          "shell.execute_reply.started": "2023-04-18T20:07:30.778259Z",
          "shell.execute_reply": "2023-04-18T20:07:34.187215Z"
        },
        "trusted": true,
        "id": "XGvTnuJyBvTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_l(w, ker_p, y_tr, Train_k, lamb, in_alp = 1, c = 0.1, P = 0.5):\n",
        "\n",
        "    Alp = in_alp\n",
        "    iteration = 100\n",
        "    ind = 0\n",
        "    ker_f = loss(w, y_tr, Train_k, lamb)\n",
        "    ker_g = np.dot(gradient(w, y_tr, Train_k, lamb).T, ker_p)\n",
        "\n",
        "    for i in range(iteration):\n",
        "        w_new = w + Alp * ker_p\n",
        "        ker_f_new = loss(w_new, y_tr, Train_k, lamb)\n",
        "\n",
        "        if ker_f_new <= ker_f + c * Alp * ker_g:\n",
        "            break\n",
        "        Alp *= P\n",
        "        ind += 1\n",
        "    return Alp"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:07:48.478866Z",
          "iopub.execute_input": "2023-04-18T20:07:48.479331Z",
          "iopub.status.idle": "2023-04-18T20:07:48.488129Z",
          "shell.execute_reply.started": "2023-04-18T20:07:48.479288Z",
          "shell.execute_reply": "2023-04-18T20:07:48.486690Z"
        },
        "trusted": true,
        "id": "uZ86U4VtBvTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BFGS_train(Train_k, y_tr, Test_k, y_test, lamb):\n",
        "\n",
        "    loss_tr = []\n",
        "    loss_test = []\n",
        "    accuracy_tr = []\n",
        "    accuracy_test = []\n",
        "\n",
        "    p = Train_k.shape[0]\n",
        "    q = Test_k.shape[0]\n",
        "    iteration = 200\n",
        "    threshold = 1e-5\n",
        "    accuracy = 0\n",
        "    w_out = np.zeros((p,1))\n",
        "\n",
        "\n",
        "    # Weight and Hessian initialization\n",
        "    w = np.zeros((p,1))\n",
        "    y_tr = y_tr.reshape(p,1)\n",
        "    y_test = y_test.reshape(q,1)\n",
        "    Ki = np.eye(p)\n",
        "    Kh = Ki\n",
        "\n",
        "    for epoch in range(iteration):\n",
        "        gd = gradient(w, y_tr, Train_k, lamb)\n",
        "        ker_p = -np.dot(Kh, gd)\n",
        "        Alp = find_l(w, ker_p, y_tr, Train_k, lamb)\n",
        "        new_w = w + Alp * ker_p\n",
        "        sk = new_w - w\n",
        "        yk = gradient(new_w, y_tr, Train_k, lamb) - gd\n",
        "        P = 1 / np.dot(yk.T, sk)\n",
        "        Ka1 = Ki - P * np.outer(sk, yk)\n",
        "        Ka2 = Ki - P * np.outer(yk, sk)\n",
        "        Ka3 = P * np.outer(sk, sk)\n",
        "        Kh = np.dot(Ka1, np.dot(Kh, Ka2)) + Ka3\n",
        "\n",
        "        w = new_w\n",
        "        tr_loss = loss(w, y_tr, Train_k, lamb)\n",
        "        train_out = predict(Train_k, w)\n",
        "        tr_a = np.mean(train_out == y_tr)\n",
        "        test_loss = loss(w, y_test, Test_k, lamb)\n",
        "        test_out = predict(Test_k, w)\n",
        "        test_a = np.mean(test_out == y_test)\n",
        "\n",
        "        if test_a > accuracy:\n",
        "            accuracy = test_a\n",
        "            w_out = np.copy(w)\n",
        "        loss_tr.append(tr_loss)\n",
        "        loss_test.append(test_loss)\n",
        "        accuracy_tr.append(tr_a)\n",
        "        accuracy_test.append(test_a)\n",
        "\n",
        "        if (epoch) % 20 == 0:\n",
        "            print(f\"Epoch {epoch}: Train Loss = {tr_loss[0][0]:.3f} \\t Train Accuracy = {tr_a*100:.2f} %\")\n",
        "\n",
        "        if sk.any() < threshold:\n",
        "            print(f\"Converged at Epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    return w_out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:27:57.898879Z",
          "iopub.execute_input": "2023-04-18T20:27:57.899299Z",
          "iopub.status.idle": "2023-04-18T20:27:57.916107Z",
          "shell.execute_reply.started": "2023-04-18T20:27:57.899262Z",
          "shell.execute_reply": "2023-04-18T20:27:57.914937Z"
        },
        "trusted": true,
        "id": "DD_gSkW6BvTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = BFGS_train(bfgs_k_train, bfgs_y_tr, bfgs_k_test, y_test, lamb = 0.005)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:28:00.478950Z",
          "iopub.execute_input": "2023-04-18T20:28:00.479351Z",
          "iopub.status.idle": "2023-04-18T20:43:11.696463Z",
          "shell.execute_reply.started": "2023-04-18T20:28:00.479313Z",
          "shell.execute_reply": "2023-04-18T20:43:11.694653Z"
        },
        "trusted": true,
        "id": "Uf4q6GG9BvTp",
        "outputId": "e7107565-683b-404f-d28a-886e7848aba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 0: Train Loss = 2755.877 \t Train Accuracy = 50.00 %\nEpoch 20: Train Loss = 585.327 \t Train Accuracy = 95.33 %\nEpoch 40: Train Loss = 411.110 \t Train Accuracy = 97.85 %\nEpoch 60: Train Loss = 396.547 \t Train Accuracy = 98.28 %\nEpoch 80: Train Loss = 396.425 \t Train Accuracy = 98.30 %\nEpoch 100: Train Loss = 396.424 \t Train Accuracy = 98.30 %\nEpoch 120: Train Loss = 396.424 \t Train Accuracy = 98.30 %\nEpoch 140: Train Loss = 396.424 \t Train Accuracy = 98.30 %\nEpoch 160: Train Loss = 396.424 \t Train Accuracy = 98.30 %\nEpoch 180: Train Loss = 396.424 \t Train Accuracy = 98.30 %\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BFGS_Test_Accuracy = \" + str(accuracy*100) + \"%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:46:20.699424Z",
          "iopub.execute_input": "2023-04-18T20:46:20.699824Z",
          "iopub.status.idle": "2023-04-18T20:46:20.706132Z",
          "shell.execute_reply.started": "2023-04-18T20:46:20.699788Z",
          "shell.execute_reply": "2023-04-18T20:46:20.704943Z"
        },
        "trusted": true,
        "id": "T84LoTzOBvTp",
        "outputId": "5710ebf6-c310-4374-8ce6-303b7927511c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "BFGS_Test_Accuracy = 94.3%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **LBFGS_Algorithm**"
      ],
      "metadata": {
        "id": "v64bf46qBvTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lbfgs_direction(gd, His_s, His_y, His_p, hist_s):\n",
        "    q = gd.copy()\n",
        "    alpha_list = [0] * hist_s\n",
        "\n",
        "    for i in range(len(His_s)-1, -1, -1):\n",
        "        rho = His_p[i]\n",
        "        alpha_list[i] = rho * np.dot(His_s[i].T, q)\n",
        "        q = q - alpha_list[i] * His_y[i]\n",
        "    Hk_0 = np.dot(His_y[-1].T, His_s[-1]) / np.dot(His_y[-1].T, His_y[-1])\n",
        "    r = Hk_0 * q\n",
        "\n",
        "    for i in range(len(His_s)):\n",
        "        rho = His_p[i]\n",
        "        beta = rho * np.dot(His_y[i].T, r)\n",
        "        r = r + His_s[i] * (alpha_list[i] - beta)\n",
        "    pk = -r\n",
        "    return pk"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:47:44.349028Z",
          "iopub.execute_input": "2023-04-18T20:47:44.349656Z",
          "iopub.status.idle": "2023-04-18T20:47:44.358444Z",
          "shell.execute_reply.started": "2023-04-18T20:47:44.349621Z",
          "shell.execute_reply": "2023-04-18T20:47:44.357188Z"
        },
        "trusted": true,
        "id": "3arLbigQBvTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_LBFGS(Train_k, y_tr, Test_k, y_test, lamb, hist_s):\n",
        "\n",
        "    iteration = 200\n",
        "    tolerance = 1e-5\n",
        "    p = Train_k.shape[0]\n",
        "    q = Test_k.shape[0]\n",
        "\n",
        "    loss_tr = []\n",
        "    loss_test = []\n",
        "    accuracy_tr = []\n",
        "    accuracy_test = []\n",
        "    accuracy = 0\n",
        "    w_out = np.zeros((p,1))\n",
        "\n",
        "    w = np.zeros((p,1))\n",
        "    y_tr = y_tr.reshape(p,1)\n",
        "    y_test = y_test.reshape(q,1)\n",
        "    His_s = []\n",
        "    His_y = []\n",
        "    His_p = []\n",
        "\n",
        "    for epoch in range(iteration):\n",
        "        gd = gradient(w, y_tr, Train_k, lamb)\n",
        "        if epoch == 0:\n",
        "            pk = -gd\n",
        "        else:\n",
        "            pk = lbfgs_direction(gd, His_s, His_y, His_p, hist_s)\n",
        "        alpha = find_l(w, pk, y_tr, Train_k, lamb)\n",
        "        new_w = w + alpha * pk\n",
        "        sk = new_w - w\n",
        "        yk = gradient(new_w, y_tr, Train_k, lamb) - gd\n",
        "        rho = 1 / np.dot(yk.T, sk)\n",
        "\n",
        "        if len(His_s) == hist_s:\n",
        "            His_s.pop(0)\n",
        "            His_y.pop(0)\n",
        "            His_p.pop(0)\n",
        "        His_s.append(sk)\n",
        "        His_y.append(yk)\n",
        "        His_p.append(rho)\n",
        "        w = new_w\n",
        "        tr_loss = loss(w, y_tr, Train_k, lamb)\n",
        "        train_out = predict(Train_k, w)\n",
        "        tr_a = np.mean(train_out == y_tr)\n",
        "        test_loss = loss(w, y_test, Test_k, lamb)\n",
        "        test_out = predict(Test_k, w)\n",
        "        test_a = np.mean(test_out == y_test)\n",
        "\n",
        "        if test_a > accuracy:\n",
        "            accuracy = test_a\n",
        "            w_out = np.copy(w)\n",
        "        loss_tr.append(tr_loss)\n",
        "        loss_test.append(test_loss)\n",
        "        accuracy_tr.append(tr_a)\n",
        "        accuracy_test.append(test_a)\n",
        "\n",
        "        if (epoch) % 20 == 0:\n",
        "            print(f\"Epoch {epoch}: Train Loss = {tr_loss[0][0]:.3f} \\t Train Accuracy = {tr_a*100:.2f} %\")\n",
        "        # Check for convergence\n",
        "        if np.linalg.norm(sk) < tolerance:\n",
        "            print(f\"Converged at Epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    return w_out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:48:48.572454Z",
          "iopub.execute_input": "2023-04-18T20:48:48.572912Z",
          "iopub.status.idle": "2023-04-18T20:48:48.587413Z",
          "shell.execute_reply.started": "2023-04-18T20:48:48.572858Z",
          "shell.execute_reply": "2023-04-18T20:48:48.586130Z"
        },
        "trusted": true,
        "id": "c4ltEaqiBvTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = train_LBFGS(bfgs_k_train, bfgs_y_tr, bfgs_k_test, y_test, lamb = 0.005, hist_s = 10)\n",
        "print()\n",
        "print(\"LBFGS_Test_Accuracy = \" + str(accuracy*100) + \"%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:49:22.204114Z",
          "iopub.execute_input": "2023-04-18T20:49:22.204567Z",
          "iopub.status.idle": "2023-04-18T20:49:35.872834Z",
          "shell.execute_reply.started": "2023-04-18T20:49:22.204524Z",
          "shell.execute_reply": "2023-04-18T20:49:35.871154Z"
        },
        "trusted": true,
        "id": "_N25oafoBvTq",
        "outputId": "633d5dc7-fb7b-4c8c-cf46-b823eedb24fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 0: Train Loss = 2755.877 \t Train Accuracy = 50.00 %\nEpoch 20: Train Loss = 1019.697 \t Train Accuracy = 90.53 %\nEpoch 40: Train Loss = 931.048 \t Train Accuracy = 90.85 %\nEpoch 60: Train Loss = 841.165 \t Train Accuracy = 92.35 %\nEpoch 80: Train Loss = 803.388 \t Train Accuracy = 92.67 %\nEpoch 100: Train Loss = 773.399 \t Train Accuracy = 92.70 %\nEpoch 120: Train Loss = 753.387 \t Train Accuracy = 93.20 %\nEpoch 140: Train Loss = 740.630 \t Train Accuracy = 93.42 %\nEpoch 160: Train Loss = 721.581 \t Train Accuracy = 93.80 %\nEpoch 180: Train Loss = 701.562 \t Train Accuracy = 94.00 %\n\nLBFGS_Test_Accuracy = 94.3%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "."
      ],
      "metadata": {
        "id": "BKYgvXVCQZyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimization algorithms are used to minimize the value of the cost function with respect to time. For different methods the reduction in cost with time vary based on optimization methods used."
      ],
      "metadata": {
        "id": "_1bbsMykQKNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From the above solution we can deduce that LBFGS is suitable for large-scale optimization problems as it is memory-efficient version of BFGS and also converges faster than GD and SGD and also converges smoothly.But, It requires Requires more memory compared to GD and SGD."
      ],
      "metadata": {
        "id": "C_nDCHteQRUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   The cost function for BFGS decreases smoothly over time.  BFGS can converge faster than GD and SGD, especially when the cost function is smooth and convex. But, requires more memory than GD and SGD because of Hessian approximation."
      ],
      "metadata": {
        "id": "F65O_hF2QTf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Gradient Descent on the other hand is a simple and widely used optimization algorithm for minimizing the cost function, and the Cost function decreases smoothly over time. But, has a tendency to converge to a local minimum for non-convex function, and can be slow when the dataset is large."
      ],
      "metadata": {
        "id": "W-9FCiCOQeH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   SGD is a variation of GD that randomly samples a subset of the data to compute the gradient which makes SGD faster than GD, especially when the dataset is large. However, because it uses only a subset of the data, the update directionis noisy and lead to fluctuations in the cost function.But this niose also helps SGD to escape local minima and converge to a better global minimum compared to GD.\n",
        "\n"
      ],
      "metadata": {
        "id": "xkm9y4XaRjn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "."
      ],
      "metadata": {
        "id": "F4H7whnCSWc3"
      }
    }
  ]
}